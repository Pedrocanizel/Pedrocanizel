..

s3 / Vídeo 32:

Serve para:

Backup, Armazenamento, Arquivamento de dados, Armazenamento de núvem hibrida, Hospedar aplicações, 
Hospedar mímia, data lake, Analytics, Delivery de software,  Site estático.

Nomes dos buckets devem ser globalmente únicos.

Buckets são definidos à nivel regional,

Parecem um serviço global, mas são criados em região.

Os objetos (arquivos) no bucket possuem uma chave, essa chave é o full path para esse objeto.
exemplo: s3://my-bucket/my_file.txt, s3://my-bucket/one_folder/my_file.txt

O tamanho máximo de um objeto é de 5tb,

Caso o arquivo possua mais de 5tb vc deve usar o "multi-part upload",

Os metadados do s3 são lista de chave/valor para identificar os objetos.

O objeto pode ter uma 'version ID' se o versionamento estiver habilitado, após desabilitar a opção de versionamento,
as versões dos seus objetos não são deletadas.


Segurança no s3 / Vídeo 34 :

Baseadas no usuário:

IAM Policies que dão as permissões de quais apis o usuário possue permissão,

Baseadas no recurso: 

Regras no bucket a partir do console do s3, que dão permissões através das contas.
ACL: Object acess control list, granularidade fina de permissões que pode ser desabilitado.
ACL Bucket acess control list: Controle de acesso à nivel do bucket

Então, quando uma pessoa pode acessar um objeto no s3? Se ela tiver permissão no IAM OU permissão no recurso
e não tiver nenhum tipo de proibição (DENY).

Encriptação: Objetos no s3 usam chaves de encriptação.

s3 Replicação / Vídeo 38:

CRR : Cross Region Replication
SRR : Same Region Replication

Para fazer replicação, primeiro devo habilitar o Versionamento dos buckets, tanto na região que eu estou, quanto
na região de destino caso eu vá fazer CRR.

Os buckets podem estar em diferentes contas da AWS,
A cópia é assíncrona.

É necessário dar permissões de leitura e escrita para o s3 para fazer a replicação.

Depois que você ativa replicação, apenas os objetos novos são replicados.

Caso você queira replicar os objetos que já existiam, vc deve usar o s3 Batch Replication.

Você pode habilitar a replicação de delete markers, nesse caso, apenas os delete markers são replicados, não acontece a deleção real do objeto


Não há encadeamento de replicações, ou seja, você replica apenas do bucket 1 para o bucket 2. Caso
o bucket 2 possua replicação com o bucket 3, ele não encadeia a replicação do 1, para o 2, para o 3 e assim sucessivamente.


s3 Storage classes / Vídeo 41:

Você pode mudar manualmente entre as classes de armazenamento ou de forma automática usando configurações de ciclo de vida.

Conceito de durabilidade: Quanto um objeto vai durar na nuvem - 99,9999999999%, 11 9's

A durabilidade é a mesma em todas das classes de armazenamento no s3.

Disponibilidade diz quão disponível um serviço é, isso varia de classe para classe de armazenamento.

s3 Standard -> Propósito geral:

- 99,99% de disponibilidade,
- Usado para acesso frequente aos dados,
- Baixa Latência e alto throughput,
- Sustain 2 concurrent facility failures?

Use cases: Big Data Analytics, mobile & gaming aplication, content distribution...

s3 infrequent acsees:

- Para dados que são menos frequentemente acessados mas requerem acesso rapido quando preciso,
- Menos custo do que s3 standard.

S3 standard-Infrequent Acess (s3 Standard-IA)
- 99,9% disponibilidae,
- Usado para disaster recovery backups

s3 one zone-infrequent acess(s3 One Zone-IA)
- 99,999999999999999% durabilidade em uma unica AZ mas o dado é destruído quando a AZ é destruída.
- 99,5% Disponibilidade.

Use cases: backups secundários de cópias do on-premise ou dado q vc pode recriar.

s3 Glacier Storage Classes:

- menores custos por armazenamento,
- Paga por armazenamento + acesso.

S3 glacier instant retrieval:
- Acesso em millisegundos, bom para dados acessados por trimestre
- Mínimo de 90 dias guardado.

s3 flacier flexible retrieval:
- Expedited (1 a 5 min), Standard (3 a 5hr), Bulk (5 a 12hr)-free,
- Mínimo de 180 dias armazenados.

s3 Inteligent-Tiering:

- Move objetos automaticamente entre as classes de armazenamento conforme uso.
- Não tem custo para acessar o dado.

A ordem de mudança dos objetos é:

Frequent acess tier (automatic) default:
Infrequent acess tier (automatic) objects not acessed for 30 days,
Archive instant access tier (automatic) objects not acessed for 90 days,
Archive acess tier (optional) configurable from 90 days to 700 + days
Deep archive access tiver (optional) config from 180 days to 700+ days.

Ver o diagrama de comparação no final do módulo.






























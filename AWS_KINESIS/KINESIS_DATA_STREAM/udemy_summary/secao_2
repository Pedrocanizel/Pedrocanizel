Real Time - Kinesis data stream, SQS, IOT,

Near Real Time - Kinesis data firehose, DMS (Database Migration Service).

Batch - Snowball, Data Pipeline

KINESIS DATA STREAM / Vídeo 8: 

- Uma ferramenta para stremar dados em uma aplicação.

- Feita de Shards (fragmentos),

- Voce pode reservar essas shards antes do tempo,

- A quantidade de shards determina sua capacidade de ingestão e consumo,

- Producers enviam dados para o KDS,

- Producers podem ser de diversas fontes como : aplicações, clients, sdk, kpl, kinesis agente...,

- Producers vão produzir "records" no KDS, 

- Um "Record" é composto de uma Partition Key e um Data Blob de até 1 mb,

- A partition key do Record determina pra qual shard o dado(Record) vai,

- Um producer pode enviar 1 mb de dados por segundo ou 1000 msg por segundo por shard.

- Uma vez que o dado está no KDS ele pode ser consumido por muitos consumers, como : KCL, SDK, kinesis data firehose, kinesis data analytics,

- Quando o consumer recebe o dado (record) ele recebe a Partition Key, O Sequence nº que é onde o dado estava dentro do shard, e o dado (data Blob),

- Para os consumers podemos ter o consumo de até 2 mb compartilhado por todos os consumers por shard, ou 2 mb por segundo por shard por consumer (Enhanced - que é uma forma mais cara)

- O período de retenção dentro do KDS é de 1 até 365 dias.

- Por padrão tem a possibilidade de reprocessar o dado,

- Uma vez que o dado é inserido no KDS ele não pode ser deletado (conceito de imutabilidade),

- Dados que compartilham a mesma partição (Partition Key) vão para o mesmo shard,

- Você pode provisionar shards com antecedência e pode também escalá-los manualmente ou por API,

- Você paga por shard provisionado por hora,

- Você pode utilizar o KDS de uma forma que é On-Demand, você não precisa provisionar os shards, eles serão ajustados ao longo do tempo conforme demanda, o padrão para esse modo é de 4 mb/seg ou 4000 msg/seg,

- A escalabilidade desse modelo on-demand é feita automaticamente através dos picos dos últimos 30 dias,

- No formato on demand vc paga por stream, por hora e por Gigabites de dados que entram e saem,

- No assunto segurança seu stream é entregue dentro de uma região, você pode controlar acessos no IAM policies, 

- O dado é encriptado em flyght usando endpoints https e em rest usando KMS, 

- Você pode implementar encriptação, 

- Existem endpoints VPCs disponíveis para acesso ao kinesis, 

- Você pode monitorar suas apis usando cloudtrail, 

KINESIS PRODUCERS / Vídeo 9: 

Existem 4 formas de se produzir dados para o KDS:

1 - Kineses SDK (que é o que produz pelo CLI), você em geral usa o método putrecord() e o putrecords() para enviar os dados. putrecords() usa batching para consumir menos requisições http.

2 - Kinesis producer library (que é uma lib mais avançada para produzir códigos). É configurada com C++ e java librarys, usada para alta performance. Possui configuração para retry. Possui apis síncronas (como o sdk) e assíncronas
para excelentes performances. Sempre que vc escreve uma aplicação com KPL vc pode monirorá-la no cloud wacth. KPL possui uma configração que é o batching, com 2 sub configs, as 2 ativadas por padrão, as 2 vão ajudar a reduzir custos
e melhorar o throughput, uma delas é o collect para vc coletar dados e escrever para vários shards na mesma requisição de API (putrecords() call), a outra é o aggregate, que aumenta latência mas melhora a eficiência tbm, você pode armazenar
multiple records e passar do limite de 1000 por segundo e tbm te ajuda a aumentar o tamanho do payload para chegar mais fácilmente ao limite de 1 mb/s. Para aumentar a eficiência do batching vc pode implementar o recordmaxbufferedtime
por exemplo em 100ms, desse forma ele vai "esperar" para poder agregar e enviar seus dados em bloco. KPL não faz compressão por default. Quando não usar o KPL? quando sua aplicação não suporta o delay aumentado que o batching agrega.

3 - Kinesis agent que é um programa linux que roda no seu server, te permite pegar um dados e enviar para o KDS. Também envia métrica para o cloud watch pq é construído encima do KPL.

KINESIS CONSUMERS / Vídeo 10: 

Podemos consumir do KDS de diferentes formas como:

1 - Kinesis SDK (CLI): através do get records.

2 - Kinesis client library KCL: é primariamente escrita em java mas existe em várias linguagens.

3 - kinesis connector library: Escreve dado para o s3, dynamodb, redshift, opensearch.

4 - Lambda

5 - kinesis firehose
Cada shard pode agregar até 2mb de dados totais para serem consumidos. Cada vez que você faz um getrecords() você pode receber até 10mb de dados, mas como vc pode receber apenas 2mb por segundo, se vc receber os 10mb vc vai precisar 
esperar 5 segundos até a proxima requisição. Outro limite é que vc pode fazer até 5 api call por segundo (200 ms de latência) por shard. 
Se eu tenho 5 consumers em 1 shard, cada um pode fazer apenas 1 requisição por segundo ( o limite é 5 por shard) e cada um pode pegar apenas 400 kb de dado (2 mb de limite).

KINESIS DATA STREAM HANDS ON / Vídeo 11: 

Enhanced fan out / Vídeo 12: 

Faz com que possamos receber 2 mb per shard per consumer, ou seja, sem isso é apenas 2mb per shard por segundo, divididos entre n consumers.
O enhanced fan out fez com que ficasse mto mais dinamico acessar os shards pelos consumers alem de reduzir a latencia em 70 ms

Quando usar Consumers padrão? 
Quando eu :
           - Tiver baixo numero de aplicações consumindo,
           - Puder tolerar +- 200 ms de latência,
           - Quando eu quiser minimizar o custo

Quando usar o Enhanced Fan-Out:
Quando eu:
           - Tiver multiplas aplicações consumindo meu Stream,
           - Quando eu precisar de baixa latência +- 70 ms,
            - Puder gastar mais.
           - Por padrão vc ter um limite de 20 consumers usando enhanced dan-out por data stream, mas pode fazer uma solicitação para aumentar isso.


Kinesis Scaling / Vídeo 13:

Operações comuns quando se escala o Kinesis:

           - 1 - Shard Splitting : Aumentar o número de shards. Pq fazer isso? Para aumentar a capacidade do seu stream, se por exemplo você possui 
10 shards, você pode receber até 10mb/s, caso queira receber mais do que isso, precisa aumentar o número de shards. Shard splitting pode ser 
usado para dividir um hot shard, um shard que está sendo mais utilizado que os outros.

- O que acontece quando você divide um Shard? O antigo é fechado e vai ser deletado quando o dado expirar. Outros 2 novos shards são criados 
e "ocupam" funcionalmente o lugar do outro. Se você divide apenas uma vez, ao invés de receber 1 mb/s vc recebe 2 mb/s. Nesse exemplo, se antes 
eu tinha 3 shards para receber informação, agora eu tenho 4. 

           - 2 - Merging Shards : Você diminui a sua capacidade de stream e economiza. Pode ser usado por exemplo para unir 2 shards com baixo uso.
Os shards antigos serão deletados quando o dado que estiver neles expirar, e apenas o novo será usado.








##########################################
##########################################
##########################################
           PERGUNTAS/DICAS
##########################################
##########################################
##########################################

- Se na prova perguntar algo sobre enviar dados de forma assíncrona para o KDS a responsta é kinesis producer library KPL.
4 - Bibliotecas de terceiros como kafka, spark...

Em geral ferramentas aws como cloud watch, aws iot podem enviar dados diretamente para o KDS.

- o exame espera que vc saiba que você pode consumir diretamente do KDS através do spark.

- uma outra questão é sobre o dynamoDB e o gargalo que ele pode ter por ter baixo WCU...

- Muito comum na certificação, cair uma questão onde o producer está enviando dado pra o KDS, com a partição correta, e por algum motivo seu
consumer recebeu dado fora de ordem por algum motivo, e dizem que a razão para isso seria o resharding. Quando você faz um resharding, vc pode ler
dos shards filhos após o resharding, mas se você não leu todo o dado do shard pai ainda você pode ler o dado fora de ordem. O indicado aqui é que
se leia todo o dado do shard pai após o reshard, até que não se tenha mais nenhum dado no shard pai para só depois ler dados dos
shards filhos. O Kinesis Client Library, possui isso implementado na sua lógica.

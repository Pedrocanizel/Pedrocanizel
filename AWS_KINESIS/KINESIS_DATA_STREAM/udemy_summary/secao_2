Real Time - Kinesis data stream, SQS, IOT,

Near Real Time - Kinesis data firehose, DMS (Database Migration Service).

Batch - Snowball, Data Pipeline

KINESIS DATA STREAM / Vídeo 8: 

- Uma ferramenta para stremar dados em uma aplicação.

- Feita de Shards (fragmentos),

- Voce pode reservar essas shards antes do tempo,

- A quantidade de shards determina sua capacidade de ingestão e consumo,

- Producers enviam dados para o KDS,

- Producers podem ser de diversas fontes como : aplicações, clients, sdk, kpl, kinesis agente...,

- Producers vão produzir "records" no KDS, 

- Um "Record" é composto de uma Partition Key e um Data Blob de até 1 mb,

- A partition key do Record determina pra qual shard o dado(Record) vai,

- Um producer pode enviar 1 mb de dados por segundo ou 1000 msg por segundo por shard.

- Uma vez que o dado está no KDS ele pode ser consumido por muitos consumers, como : KCL, SDK, kinesis data firehose, kinesis data analytics,

- Quando o consumer recebe o dado (record) ele recebe a Partition Key, O Sequence nº que é onde o dado estava dentro do shard, e o dado (data Blob),

- Para os consumers podemos ter o consumo de até 2 mb compartilhado por todos os consumers por shard, ou 2 mb por segundo por shard por consumer (Enhanced - que é uma forma mais cara)

- O período de retenção dentro do KDS é de 1 até 365 dias.

- Por padrão tem a possibilidade de reprocessar o dado,

- Uma vez que o dado é inserido no KDS ele não pode ser deletado (conceito de imutabilidade),

- Dados que compartilham a mesma partição (Partition Key) vão para o mesmo shard,

- Você pode provisionar shards com antecedência e pode também escalá-los manualmente ou por API,

- Você paga por shard provisionado por hora,

- Você pode utilizar o KDS de uma forma que é On-Demand, você não precisa provisionar os shards, eles serão ajustados ao longo do tempo conforme demanda, o padrão para esse modo é de 4 mb/seg ou 4000 msg/seg,

- A escalabilidade desse modelo on-demand é feita automaticamente através dos picos dos últimos 30 dias,

- No formato on demand vc paga por stream, por hora e por Gigabites de dados que entram e saem,

- No assunto segurança seu stream é entregue dentro de uma região, você pode controlar acessos no IAM policies, 

- O dado é encriptado em flyght usando endpoints https e em rest usando KMS, 

- Você pode implementar encriptação, 

- Existem endpoints VPCs disponíveis para acesso ao kinesis, 

- Você pode monitorar suas apis usando cloudtrail, 

KINESIS PRODUCERS / Vídeo 9: 

Existem 4 formas de se produzir dados para o KDS:

1 - Kineses SDK (que é o que produz pelo CLI), você em geral usa o método putrecord() e o putrecords() para enviar os dados. putrecords() usa batching para consumir menos requisições http.

2 - Kinesis producer library (que é uma lib mais avançada para produzir códigos). É configurada com C++ e java librarys, usada para alta performance. Possui configuração para retry. Possui apis síncronas (como o sdk) e assíncronas
para excelentes performances. Sempre que vc escreve uma aplicação com KPL vc pode monirorá-la no cloud wacth. KPL possui uma configração que é o batching, com 2 sub configs, as 2 ativadas por padrão, as 2 vão ajudar a reduzir custos
e melhorar o throughput, uma delas é o collect para vc coletar dados e escrever para vários shards na mesma requisição de API (putrecords() call), a outra é o aggregate, que aumenta latência mas melhora a eficiência tbm, você pode armazenar
multiple records e passar do limite de 1000 por segundo e tbm te ajuda a aumentar o tamanho do payload para chegar mais fácilmente ao limite de 1 mb/s. Para aumentar a eficiência do batching vc pode implementar o recordmaxbufferedtime
por exemplo em 100ms, desse forma ele vai "esperar" para poder agregar e enviar seus dados em bloco. KPL não faz compressão por default. Quando não usar o KPL? quando sua aplicação não suporta o delay aumentado que o batching agrega.

3 - Kinesis agent que é um programa linux que roda no seu server, te permite pegar um dados e enviar para o KDS. Também envia métrica para o cloud watch pq é construído encima do KPL.

KINESIS CONSUMERS / Vídeo 10: 

Podemos consumir do KDS de diferentes formas como:

1 - Kinesis SDK (CLI): através do get records.

2 - Kinesis client library KCL: é primariamente escrita em java mas existe em várias linguagens.

3 - kinesis connector library: Escreve dado para o s3, dynamodb, redshift, opensearch.

4 - Lambda

5 - kinesis firehose
Cada shard pode agregar até 2mb de dados totais para serem consumidos. Cada vez que você faz um getrecords() você pode receber até 10mb de dados, mas como vc pode receber apenas 2mb por segundo, se vc receber os 10mb vc vai precisar 
esperar 5 segundos até a proxima requisição. Outro limite é que vc pode fazer até 5 api call por segundo (200 ms de latência) por shard. 
Se eu tenho 5 consumers em 1 shard, cada um pode fazer apenas 1 requisição por segundo ( o limite é 5 por shard) e cada um pode pegar apenas 400 kb de dado (2 mb de limite).

KINESIS DATA STREAM HANDS ON / Vídeo 11: 

Enhanced fan out / Vídeo 12: 

Faz com que possamos receber 2 mb per shard per consumer, ou seja, sem isso é apenas 2mb per shard por segundo, divididos entre n consumers.
O enhanced fan out fez com que ficasse mto mais dinamico acessar os shards pelos consumers alem de reduzir a latencia em 70 ms

Quando usar Consumers padrão? 
Quando eu :
           - Tiver baixo numero de aplicações consumindo,
           - Puder tolerar +- 200 ms de latência,
           - Quando eu quiser minimizar o custo

Quando usar o Enhanced Fan-Out:
Quando eu:
           - Tiver multiplas aplicações consumindo meu Stream,
           - Quando eu precisar de baixa latência +- 70 ms,
            - Puder gastar mais.
           - Por padrão vc ter um limite de 20 consumers usando enhanced dan-out por data stream, mas pode fazer uma solicitação para aumentar isso.


Kinesis Scaling / Vídeo 13:

Operações comuns quando se escala o Kinesis:

           - 1 - Shard Splitting : Aumentar o número de shards. Pq fazer isso? Para aumentar a capacidade do seu stream, se por exemplo você possui 
10 shards, você pode receber até 10mb/s, caso queira receber mais do que isso, precisa aumentar o número de shards. Shard splitting pode ser 
usado para dividir um hot shard, um shard que está sendo mais utilizado que os outros.

- O que acontece quando você divide um Shard? O antigo é fechado e vai ser deletado quando o dado expirar. Outros 2 novos shards são criados 
e "ocupam" funcionalmente o lugar do outro. Se você divide apenas uma vez, ao invés de receber 1 mb/s vc recebe 2 mb/s. Nesse exemplo, se antes 
eu tinha 3 shards para receber informação, agora eu tenho 4. 

           - 2 - Merging Shards : Você diminui a sua capacidade de stream e economiza. Pode ser usado por exemplo para unir 2 shards com baixo uso.
Os shards antigos serão deletados quando o dado que estiver neles expirar, e apenas o novo será usado.

Auto scaling não está implementado por padrão no KDS, mas existe uma API para mudar o número de shards. Pode se implementar o auto-scaling
com Lambda.

Limitações:

Você não pode fazer resharding em paralelo. Por isso você deve se planejar para fazer isso. Você pode fazer apenas uma por vez e leva alguns 
segundos para acabar. Por exemplo, se vc tem 1000 shards, levaria +- 30.000 segundos para dobrar o número de shards, ou seja, 8,3 horas


Lidando com duplicados para Producers / Vídeo 14:

Existem 2 formas do dado duplicar no KDS, do lado do Producer e do lado do Consumer.

Os Producers retries podem criar dados duplicados causados por "network timeous". O producer não recebe um akwnoledgmente
e acha que o dado não chegou. Para lidar com esse problema é importante ter uma chave única produzida no lado do consumder.

Um consumer retry pode fazer dado duplicado de 4 formas diferentes. Todas essas 4 formas possuem relação com quando o record process restart.

1 - Quando um worker termina inexperadamente,
2 - Quando instancias de worker são adicionadas ou removidas,
3 - Quando shards são unidos(merges) ou divididos(splitting),
4 - Quando é feito o deploy da aplicação.

Solução: Fazer com que o destino final possa lidar com dado duplicado.

Segurança / Vídeo 15:

- Controlamos acessos e autorizações no kinesis usando IAM policies.
- Possui encriptação no vôo (in flight) usando HTTPS endpoints, ou seja, não pode ser interceptado.
- Podemos ter Encriptação at rest usando KMS
- Caso vc deseje ter encriptação no seu lado, deve implementar.
- Caso você queira acessar o Kineses de uma VPC (internet privada) e não pela internet pública, vc pode implementar VPC endpoints.


Kinesis Data Firehose / Vídeo 16:

Kinesis data firehose pode ler de diferentes fontes/Producers como:

- Aplicações,
- Client,
- SDK, KPL,
- Kinesis Agent,
- Kinesis data stream,
- Amazon Cloud watch (logs & events),
- AWS IOT

Você lê uma linha por vêz, podendo ter até 1 mb cada.

Se você quiser transformar o dado, deve usar Lambda function.

Após receber o dado, o KDF não evnvia instantâneamente, ele armazena para enviar de forma eficiente.
Desta forma, é um serviço Near real time (próximo ao tempo real), não em tempo real. 60 segundos de latência mínima para batches que não ficaram completos.

Podemos ter 3 destinos para os dados que chegam no KDF,

1 - Amazon s3,
2 - Amazon Redshift,
3 - Amazon OpenSearch

4*** - Splunk

KDF também pode enviar dados para alguns terceiros e tbm para destinos que possuam um endpont http válido.

Você pode armazenar todos os dados do KDF no s3, ou apenas os dados que falharem.

Possui escalabilidade automática.

Possui suporte para muitos formatos de dados, 

Possui suporte para conversão de JSON para Parquet/ORC apenas se vc usar o s3.

Outras transformações de dados, vc vai precisar do Lambda.

Suporta compressão,

Apenas gzip pode ser carregado no Redshift,

Você paga apenas pelo dado que passa através do KDF.

SPARK e KCL não lêem do KDF.

SPARK e KCL lêem apenas do KDS.

Como conseguimos por todo o dado que passa pelo KDF no s3? A resposta é que isso é uma funcionalidade do KDF.



















##########################################
##########################################
##########################################
           PERGUNTAS/DICAS
##########################################
##########################################
##########################################

- Se na prova perguntar algo sobre enviar dados de forma assíncrona para o KDS a responsta é kinesis producer library KPL.
4 - Bibliotecas de terceiros como kafka, spark...

Em geral ferramentas aws como cloud watch, aws iot podem enviar dados diretamente para o KDS.

- o exame espera que vc saiba que você pode consumir diretamente do KDS através do spark.

- uma outra questão é sobre o dynamoDB e o gargalo que ele pode ter por ter baixo WCU...

- Muito comum na certificação, cair uma questão onde o producer está enviando dado pra o KDS, com a partição correta, e por algum motivo seu
consumer recebeu dado fora de ordem por algum motivo, e dizem que a razão para isso seria o resharding. Quando você faz um resharding, vc pode ler
dos shards filhos após o resharding, mas se você não leu todo o dado do shard pai ainda você pode ler o dado fora de ordem. O indicado aqui é que
se leia todo o dado do shard pai após o reshard, até que não se tenha mais nenhum dado no shard pai para só depois ler dados dos
shards filhos. O Kinesis Client Library, possui isso implementado na sua lógica.

- Os Producers retries podem criar dados duplicados causados por "network timeous". É uma questão do exame. O producer não recebe um akwnoledgmente
e acha que o dado não chegou. 

Um consumer retry pode fazer dado duplicado de 4 formas diferentes. Todas essas 4 formas possuem relação com quando o record process restart.

1 - Quando um worker termina inexperadamente,
2 - Quando instancias de worker são adicionadas ou removidas,
3 - Quando shards são unidos(merges) ou divididos(splitting),
4 - Quando é feito o deploy da aplicação.

SPARK e KCL não lêem do KDF.

SPARK e KCL lêem apenas do KDS.

Como conseguimos por todo o dado que passa pelo KDF no s3? A resposta é que isso é uma funcionalidade do KDF.


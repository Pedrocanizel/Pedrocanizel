Real Time - Kinesis data stream, SQS, IOT,

Near Real Time - Kinesis data firehose, DMS (Database Migration Service).

Batch - Snowball, Data Pipeline

KINESIS DATA STREAM / Vídeo 8: 

- Uma ferramenta para stremar dados em uma aplicação.

- Feita de Shards (fragmentos),

- Voce pode reservar essas shards antes do tempo,

- A quantidade de shards determina sua capacidade de ingestão e consumo,

- Producers enviam dados para o KDS,

- Producers podem ser de diversas fontes como : aplicações, clients, sdk, kpl, kinesis agente...,

- Producers vão produzir "records" no KDS, 

- Um "Record" é composto de uma Partition Key e um Data Blob de até 1 mb,

- A partition key do Record determina pra qual shard o dado(Record) vai,

- Um producer pode enviar 1 mb de dados por segundo ou 1000 msg por segundo por shard.

- Uma vez que o dado está no KDS ele pode ser consumido por muitos consumers, como : KCL, SDK, kinesis data firehose, kinesis data analytics,

- Quando o consumer recebe o dado (record) ele recebe a Partition Key, O Sequence nº que é onde o dado estava dentro do shard, e o dado (data Blob),

- Para os consumers podemos ter o consumo de até 2 mb compartilhado por todos os consumers por shard, ou 2 mb por segundo por shard por consumer (Enhanced - que é uma forma mais cara)

- O período de retenção dentro do KDS é de 1 até 365 dias.

- Por padrão tem a possibilidade de reprocessar o dado,

- Uma vez que o dado é inserido no KDS ele não pode ser deletado (conceito de imutabilidade),

- Dados que compartilham a mesma partição (Partition Key) vão para o mesmo shard,

- Você pode provisionar shards com antecedência e pode também escalá-los manualmente ou por API,

- Você paga por shard provisionado por hora,

- Você pode utilizar o KDS de uma forma que é On-Demand, você não precisa provisionar os shards, eles serão ajustados ao longo do tempo conforme demanda, o padrão para esse modo é de 4 mb/seg ou 4000 msg/seg,

- A escalabilidade desse modelo on-demand é feita automaticamente através dos picos dos últimos 30 dias,

- No formato on demand vc paga por stream, por hora e por Gigabites de dados que entram e saem,

- No assunto segurança seu stream é entregue dentro de uma região, você pode controlar acessos no IAM policies, 

- O dado é encriptado em flyght usando endpoints https e em rest usando KMS, 

- Você pode implementar encriptação, 

- Existem endpoints VPCs disponíveis para acesso ao kinesis, 

- Você pode monitorar suas apis usando cloudtrail, 

KINESIS PRODUCERS / Vídeo 9: 

Existem 4 formas de se produzir dados para o KDS:

1 - Kineses SDK (que é o que produz pelo CLI), você em geral usa o método putrecord() e o putrecords() para enviar os dados. putrecords() usa batching para consumir menos requisições http.

2 - Kinesis producer library (que é uma lib mais avançada para produzir códigos). É configurada com C++ e java librarys, usada para alta performance. Possui configuração para retry.

3 - Kinesis agent que é um programa linux que roda no seu server, te permite pegar um dados e enviar para o KDS.

4 - Bibliotecas de terceiros como kafka, spark...

Em geral ferramentas aws como cloud watch, aws iot podem enviar dados diretamente para o KDS.

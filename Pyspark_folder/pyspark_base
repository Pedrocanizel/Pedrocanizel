
pip install msal -q

from pyspark.sql.functions import col, to_date, when, lit, upper, lower, explode
from pyspark.sql.functions import regexp_replace as RR
from pyspark.sql.functions import when as when
import pyspark.sql.functions as F
import pyspark.sql.types as T
from pyspark.sql.functions import initcap, col, date_add, lit, translate
import msal

###explodes############################################################################

#Step 1
df_ocorrencias = df_ocorrencias.select('id', 'occurrences.spaceId', 'occurrences')\
                         .withColumn('spaceId', F.explode('spaceId'))\
                         .withColumn('preco', F.col('occurrences.rule.price'))\
                         .withColumn('data_start', F.col('occurrences.rule.startsOn'))

#Step 2
                         
df_ocorrencias = df_ocorrencias.select("id", "spaceId", "preco", "data_start")\
                  .withColumn('preco', F.explode('preco'))\
                  .withColumn('data_start', F.explode('data_start'))
                  
#######################################################################################                  
                  

df_ocorrencias = df_ocorrencias.select('id', 'data_start', 'spaceId', 'preco') \
    .withColumn('preco', F.lower(F.col('preco')))\
    .withColumn('contem', F.col('preco').contains('grat'))


______________________________________________________________________________
@F.udf
def tratamento(col1, col2):
    
    if col2 == True or col1.strip() == "" or col1.strip() == "entrada gratuita." or col1.strip() == "livre" or col1.strip() == "gratuita" or col1.strip() == "serviço gratuito. necessário aquisição de ingresso para visita ao museu."  or col1.strip() == "gratuito, mediante retirada de ingresso na bilheteria." or col1.strip() == "gratuita" or col1.strip() == "gratuito, mediante retirada de ingresso na bilheteria." or col1.strip() == "entrada franca." or col1.strip() == "gratuito" or col1.strip() == "grátis" or col1.strip() == "0000" or col1.strip() == "00,00" or col1.strip() == "0" or col1.strip() == "r$ 00,00" or col1.strip() == "r$ 0,00" or col1.strip() == "0,00" or col1.strip() == "00" or col1.strip() == "-":
        
        col1 = "entrada franca"
        return col1
        
    if col1.strip() == "1144768,83" or col1.strip() == "ver site":
        col1 = "inconclusivo"
        return col1
    
df_ocorrencias = df_ocorrencias.withColumn('preco', tratamento(F.col('preco'), F.col('contem')))
________________________________________________________________________________

######fillna##################################################################

df_ocorrencias = df_ocorrencias.fillna(value= "pago", subset= ["preco"]) #subset = nome da coluna

df_eventos = df_eventos.na.fill(value = "Nao informado", subset = ["trad_libras"])

df_eventos = df_eventos.na.fill(value = "https://antigo.museus.gov.br/museus-do-brasil/", subset = ["site_event"])

df_museus = df_museus.fillna("Sem descriçao", subset=["descricao"])

df_museus = df_museus.fillna(value="Pública", subset=["esfera"])
     
##############################################################################

______________________________________________________________________________
#####alias####################################################################

df_ocorrencias = df_ocorrencias.select(col("id").alias("id_evento"), "data_start", col("preco").alias("price_evento"), col("spaceId").alias("id_museu"))

df_eventos = df_eventos.select(col("id").alias("id_evento"),
                                           col("longDescription").alias("descri_event"),
                                           col("name").alias("nome_event"),
                                           col("site").alias("site_event"),
                                           col("traducaoLibras").alias("trad_libras"))

df_museus = df_museus.select(col("endereco").alias("endereco_completo"),
                                       col("En_estado").alias("estado"),
                                       col("id").alias("id_museu"),
                                       col("location.latitude").alias("latitude"),
                                       col("location.longitude").alias("longitude"),
                                       col("name").alias("nome_museu"),
                                       col("shortDescription").alias("descricao"),
                                       col("esfera")
                                      )
##############################################################################

_____________________________________________________________________________
#####drop column duplicates###################################################

df_ocorrencias = df_ocorrencias.dropDuplicates()

df_eventos = df_eventos.na.drop(subset=["descri_event"])
##############################################################################


_____________________________________________________________________________
#####cast####################################################################

df_ocorrencias = df_ocorrencias.withColumn("id_evento", col("id_evento").cast("int"))
df_ocorrencias = df_ocorrencias.withColumn("id_museu", col("id_museu").cast("int"))
df_ocorrencias = df_ocorrencias.withColumn("data_start", col("data_start").cast("date"))

df_eventos = df_eventos.withColumn("id_evento", col("id_evento").cast("int"))

df_museus = df_museus.withColumn("id_museu", col("id_museu").cast("int"))
df_museus = df_museus.withColumn("latitude", col("latitude").cast("float"))
df_museus = df_museus.withColumn("longitude",col("longitude").cast("float"))
df_museus.printSchema() #printSchema ou ações no final não salvam

event = event.withColumn("id_evento", F.col("id_evento").cast("int"))\
               .withColumn("nome_evento", F.col("nome_evento").cast("string"))\
               .withColumn("descricao_evento", F.col("descricao_evento").cast("string"))\
               .withColumn("data_aleatoria", F.col("data_aleatoria").cast("date"))\
               .withColumn("frequencia_evento", F.col("frequencia_evento").cast("string"))\
               .withColumn("data_inicio", F.col("data_inicio").cast("date"))\
               .withColumn("data_final", F.col("data_final").cast("date"))
               


df2= (df.withColumn("id", df["id"].cast('int'))

         .withColumn("nome", df["nome"].cast('string'))

         .withColumn("idade", df["idade"].cast('int'))

         .withColumn("gen", df["gen"].cast('string'))

)

df2_cast = df2.select(F.col('novo_valor').cast('string'))

#criar um cast na nova coluna dentro do proprio dataframe df1
df1 = df1.withColumn('novo_valor', F.lit('valor').cast('string'))

df1 = df1.withColumn('data', df1.data.cast('timestamp'))


df1 = df1.withColumn('casosNovos', df1.casosNovos.cast('integer'))


#criando um cast para converter os valores interger em string, expressão que aceita comando SQL
df3 = df1.selectExpr('cast(obitosNovos as string)')


df5 = (
    df1.withColumn('ano', F.substring('data', 1, 4).cast('integer'))
    .withColumn('mes', F.substring('data', 6, 2).cast('integer'))
    .withColumn('dia', F.substring('data', 9, 2).cast('integer'))
    )
     
##############################################################################


_____________________________________________________________________________
#####join####################################################################


result= (df_museus
.withColumn('left', F.lit(True))
.join(df_ocorrencias.withColumn('right', F.lit(True)),
on=['id_museu'],
how='left')
.withColumn("_merge", F.when(F.col('left').isNull(), "right_only").when(F.col('right').isNull(), "left_only").otherwise("both")))


df_join_ocorrencias_evento = (df_ocorrencias.join(df_eventos,
                               'id_evento',
                               how = 'inner'))

##############################################################################


#####filter where#############################################################

df_ocorrencias = result.select('id_evento', 'id_museu', 'data_start','price_evento').filter(result['_merge'] == 'both')

df_ocorrencias = df_ocorrencias.filter(~col("id_evento").contains("3931"))
df_ocorrencias = df_ocorrencias.filter(~col("id_evento").contains("8101"))
df_ocorrencias = df_ocorrencias.filter(~col("id_evento").contains("5089"))

df_eventos = df_eventos.filter(~col("nome_event").contains("teste"))

df_eventos = df_eventos.filter(~col("id_evento").contains("5089"))

    # Display dos Enderecos nulos
df_museus_nulos = df_museus.where(col("endereco_completo").isNull()).display()

df_fato.filter(df_fato.nome_aluno.contains('1')).collect()

df2.select(F.col('regiao'), F.col('estado'), F.col('casosNovos')).filter(F.col('regiao') == 'Sul').show(20)

df2.select(F.col("regiao"),
           F.col("estado"),
           F.col("casosNovos"))\
           .filter("regiao = 'Sudeste'")\
           .show(10)
           
df2.select(F.col('regiao'), F.col('estado'), F.col('casosNovos')).filter(df2.regiao == 'Nordeste').show()     


filtro = F.col('regiao') == 'Sul'
df2.select(F.col('regiao'), F.col('estado'), F.col('casosNovos')).filter(filtro).show(15)

#aplicar mais de um filtro dentro do dataframe
#fazer filtragem pela regiao norte e estado do amazonas
df2.select(F.col('regiao'), F.col('estado'), F.col('casosNovos')).filter(F.col('regiao') == 'Norte').filter(F.col('estado') == 'AM').show()

#segunda maneira de utilizar filter mais de uam vez
df2.filter("regiao = 'Norte' and estado = 'AM'").show(10)

#terceira maneira de utilizar filter mais de uam vez
df2.filter((F.col('regiao') == 'Norte') & (F.col('estado') == 'AM')).show()

df2.where((F.col('regiao') == 'Sul') & (F.col('estado') ==  'RS')).show(10)

#utilizando o ,like para consultar substrings especificas dentrode uma coluna
df2.where((F.col('regiao') == 'Norte')).filter('estado like "R%"').show(10)


#utilizando o ,like para consultar substrings especificas dentrode uma coluna, final
df2.where((F.col('regiao') == 'Norte')).filter('estado like "%A"').show(10)


#utilizando o ,like para consultar substrings especificas dentrode uma coluna,inicio e final
df2.where((F.col('regiao') == 'Norte')).filter('estado like "%A%"').show(200)

#utilizar o filro com mais de uma condição
df2.filter("regiao in('Norte', 'Sul')").show(500)


#filtro com lista de regiao
lista_regiao = ['Norte', 'Sul']
df2.filter(F.col('regiao').isin(lista_regiao)).show(500)

#utilizando o filtro de uma forma parecida com o likem, mas com func especifica
df2.filter(F.col("regiao").startswith("Sul")).show()

#utilizando o like como uma função
df2.filter(F.col('regiao').like('C%')).show(100)
##############################################################################

                           
_____________________________________________________________________________
#####when####################################################################

df_eventos = df_eventos.withColumn("descri_event",
                when(df_eventos.descri_event == "", lit("Não informada"))
               .otherwise(df_eventos.descri_event))
               
               
df_museus = df_museus.withColumn("regiao",
                when((df_museus.estado == "RJ"), lit("SUDESTE")) 
               .when((df_museus.estado == "ES"), lit("SUDESTE")) 
               .when((df_museus.estado == "SP"), lit("SUDESTE")) 
               .when((df_museus.estado == "MG"), lit("SUDESTE")) 
               .when((df_museus.estado == "RS"), lit("SUL"))                                        
               .when((df_museus.estado == "SC"), lit("SUL")) 
               .when((df_museus.estado == "PR"), lit("SUL"))               
               .when((df_museus.estado == "MT"), lit("CENTRO OESTE")) 
               .when((df_museus.estado == "GO"), lit("CENTRO OESTE")) 
               .when((df_museus.estado == "DF"), lit("CENTRO OESTE")) 
               .when((df_museus.estado == "MS"), lit("CENTRO OESTE")) 
               .when((df_museus.estado == "PI"), lit("NORDESTE"))                                           
               .when((df_museus.estado == "PB"), lit("NORDESTE")) 
               .when((df_museus.estado == "SE"), lit("NORDESTE")) 
               .when((df_museus.estado == "RN"), lit("NORDESTE")) 
               .when((df_museus.estado == "MA"), lit("NORDESTE"))  
               .when((df_museus.estado == "AL"), lit("NORDESTE")) 
               .when((df_museus.estado == "BA"), lit("NORDESTE")) 
               .when((df_museus.estado == "PE"), lit("NORDESTE")) 
               .when((df_museus.estado == "CE"), lit("NORDESTE")) 
               .when((df_museus.estado == "AM"), lit("NORTE")) 
               .when((df_museus.estado == "RO"), lit("NORTE")) 
               .when((df_museus.estado == "AC"), lit("NORTE")) 
               .when((df_museus.estado == "PA"), lit("NORTE")) 
               .when((df_museus.estado == "TO"), lit("NORTE")) 
               .when((df_museus.estado == "AP"), lit("NORTE")) 
               .when((df_museus.estado == "RR"), lit("NORTE"))
               .otherwise(df_museus.estado))
               
               
df_museus = df_museus.withColumn("endereco_completo", 
    when(df_museus.id_museu == ("25282") , RR(df_museus.endereco_completo, "Sem Endereco", "R. Herny Hugo Dreher, 127 - Planalto, Bento Gonçalves - RS, 95700-000"))
    .when(df_museus.id_museu == ("25288") , RR(df_museus.endereco_completo, "Sem Endereco", "R. Venâncio Aires, 50, São João do Oeste - 89897-000, SC"))
    .when(df_museus.id_museu == ("25323") , RR(df_museus.endereco_completo, "Sem Endereco", "União, Imperatriz - 65900-490, MA"))
    .when(df_museus.id_museu == ("25344") , RR(df_museus.endereco_completo, "Sem Endereco", "R. São Pedro, 400 - Jardim Luciana, Santa Gertrudes - SP, 13510-000"))
    .otherwise(df_museus.endereco_completo))    
    
    
df_mu = (event.withColumn("data_aleatoria", F.when(F.col('data_aleatoria') == " ", 'Não informado')
.otherwise(F.col('data_aleatoria'))))      
    
    
df_stage_bootcamp = df_stage_bootcamp.withColumn('residentes', \
       when(F.col('residentes')=='' ,'2') \
          .otherwise(F.col('residentes')))    
                              
 
 df2 = (df1.withColumn('status', F.when(F.col('casosNovos')>0, 'Tem casos novos')
.otherwise('Nao tem casos novos')))


df3 = (df1.withColumn("status", 
          F.when(F.col("casosNovos") > 0, F.concat(df1.casosNovos,F.lit(" casos novos")))
          .otherwise("Não tem casos novos")))
     
##############################################################################
              
                                           
_____________________________________________________________________________
                                      
# ler arquivo dos eventos
df_eventos = spark.read \
.option("delimiter", ",") \
.option("header", "true") \
.json("dbfs:/mnt/pedro-canizela/link2") 


df1 = spark.read.format("csv").option("header", True).option("inferSchema", True).options(delimiter=';').load(local_arquivo)

#segunda maneira
lista_esquema = ['UM', 'DOIS', 'TRES', 'QUATRO', 'CINCO', 'SEIS', 'SETE']
df1 = (spark
       .read
       .format("csv")
       .option("header", "false")
       .option("inferschema", "false")
       .option("delimiter", ";")
       .load('/content/drive/MyDrive/datasets/arquivo_geral.csv').toDF(*lista_esquema)
)

#TERCEIRA MANEIRA - UTILIZANDO O SELECT COM F.COL E ALIAS
df2 = (spark
       .read
       .format("csv")
       .option("header", "false")
       .option("inferschema", "false")
       .option("delimiter", ";")
       .load('/content/drive/MyDrive/datasets/arquivo_geral.csv')
)



##############################################################################

_____________________________________________________________________________
#####Regex Replace################################################################
df_museus = df_museus.withColumn("endereco_completo", 
    when(df_museus.id_museu == ("25282") , RR(df_museus.endereco_completo, "Sem Endereco", "R. Herny Hugo Dreher, 127 - Planalto, Bento Gonçalves - RS, 95700-000"))
    .when(df_museus.id_museu == ("25288") , RR(df_museus.endereco_completo, "Sem Endereco", "R. Venâncio Aires, 50, São João do Oeste - 89897-000, SC"))
    .when(df_museus.id_museu == ("25323") , RR(df_museus.endereco_completo, "Sem Endereco", "União, Imperatriz - 65900-490, MA"))
    .when(df_museus.id_museu == ("25344") , RR(df_museus.endereco_completo, "Sem Endereco", "R. São Pedro, 400 - Jardim Luciana, Santa Gertrudes - SP, 13510-000"))
    .otherwise(df_museus.endereco_completo))
    
    
def mudar_virgula_para_ponto(coluna):
    global df1
    df1 = df1.withColumn(f"{coluna}", RR(f"{coluna}",",","."))

mudar_virgula_para_ponto("Unit Price")
mudar_virgula_para_ponto("Unit Cost")
mudar_virgula_para_ponto("Total Revenue")
mudar_virgula_para_ponto("Total Cost")
mudar_virgula_para_ponto("Total Profit")

df1.withColumnRenamed("Sales Channel","Sales_Chanel")    



df_selecionados = df_selecionados.withColumn('nascimento',F.regexp_replace(F.col('nascimento'),'  ',' ').alias('nascimento'))\
.withColumn('nascimento',F.to_date(F.col('nascimento'),'MMM d yyyy h:ma'))
    
_____________________________________________________________________________
#####Distinct################################################################
df_museus.select("estado").distinct().display()
                                     

df_museus.select('esfera').distinct().display()


############################################################################## 


_____________________________________________________________________________
#####renomear, rename, withcolumn ###########################################
def mudar_virgula_para_ponto(coluna):
    global df1
    df1 = df1.withColumn(f"{coluna}", RR(f"{coluna}",",","."))

mudar_virgula_para_ponto("Unit Price")
mudar_virgula_para_ponto("Unit Cost")
mudar_virgula_para_ponto("Total Revenue")
mudar_virgula_para_ponto("Total Cost")
mudar_virgula_para_ponto("Total Profit")

df1.withColumnRenamed("Sales Channel","Sales_Chanel")


selecionados = ['nome','sobrenome','cpf','nascimento','mail',
                'tel','raca','cep1','endereco1','numero1','compl',
                'cidade1','estado1','escolaridade','formacao','tecnologia',
                'bootcamp','residente','programa','def','gen','cadastro']

for c,n in zip(df_selecionados.columns,selecionados):
    df_selecionados = df_selecionados.withColumnRenamed(c,n)

############################################################################## 


_____________________________________________________________________________
#####to_date, data, mudar data### ###########################################
df1 = df1.withColumn("Order Date", F.to_date(F.col("Order Date"), 'dd/MM/yyyy'))
df1 = df1.withColumn("Ship Date", F.to_date(F.col("Ship Date"), 'dd/MM/yyyy'))


df_selecionados = df_selecionados.withColumn('nascimento',F.regexp_replace(F.col('nascimento'),'  ',' ').alias('nascimento'))\
.withColumn('nascimento',F.to_date(F.col('nascimento'),'MMM d yyyy h:ma'))


############################################################################## 

_____________________________________________________________________________
#####initcap, capitalizado, letra maiúscula##################################
df_stage_bootcamp = df_stage_bootcamp.withColumn('endereco', initcap(col('endereco')))\
  .withColumn('complemento', initcap(col('complemento')))\
  .withColumn('cidade', initcap(col('cidade')))\
  .withColumn('como_conheceu', initcap(col('como_conheceu')))


############################################################################## 


_____________________________________________________________________________
#####len, tamamho############################################################

len(df_selecionados.columns)



############################################################################## 


_____________________________________________________________________________
#####translate###############################################################
df_selecionados = df_selecionados.select('*', F.translate(F.col('nome_aluno'), '1', '').alias('translate'))
     

_____________________________________________________________________________
#####slice columns###########################################################

df_selecionados = df_selecionados.select(df_selecionados.columns[1:43])



##############################################################################


_____________________________________________________________________________
#####see columns#############################################################
df_selecionados.columns #Ver colunas



##############################################################################


_____________________________________________________________________________
#####head####################################################################
df_selecionados.head(1)


##############################################################################


_____________________________________________________________________________
#####merge####################################################################

df_fato = (df_stage_bootcamp.withColumn('left', F.lit(True))
                            .join(df_selecionados.withColumn('right', F.lit(True)),
                            on=['cpf'],
                            how='left')
                            .withColumn("_merge", F.when(F.col('left').isNull(), "right_only")
                            .when(F.col('right').isNull(),"left_only").otherwise("both"))
                            .dropDuplicates())
                            



df_fato = df_fato.withColumn('_merge', when(df_fato._merge == 'both','aprovado')
                   .when(df_fato._merge =='left_only','reprovado'))\
                   .withColumnRenamed('_merge','status_aluno')\
                   .withColumnRenamed('age','idade')
##############################################################################    


_____________________________________________________________________________
#####Criando Dataframe####################################################################


dados = [
      ('João da Silva', 'São Paulo', 'SP', 1100.00),
      ('Maria dos Santos', 'São Paulo', 'SP', 2100.00),
      ('Carlos Vítor', 'Rio de Janeiro', 'RJ', 2100.00),
      ('Phylyp Cavalcante', 'Fortaleza', 'CE', 3600.00)
]
schema = ['nome', 'cidade', 'estado', 'salario']
df = spark.createDataFrame(data=dados, schema=schema)


############################################################################## 

_____________________________________________________________________________
#####select####################################################################

df2.select('regiao', 'estado', 'data', 'casosNovos').show()


df2.select(F.col('regiao'), F.col('estado'),F.col('data'), F.col('casosNovos')).show(20)

#CRIANDO UMA LISTA DINÂMICA COM VÁRIAS COLUNAS PARA SE UTILIZAR DENTRO DO COMANDO SELECT
lista_coluna = ['regiao', 'estado', 'casosNovos', 'obitosNovos', 'obitosAcumulados']
df2.select(lista_coluna).show(20)

############################################################################## 

_____________________________________________________________________________
#####count####################################################################
print((df2.count(), len(df2.columns)))

for c in df.columns: #Percorrendo colunas e contando erros, errors,

  num = df.filter(F.col(c)== '?').count()

  print(c,num)


##############################################################################

_____________________________________________________________________________
#####like####################################################################

#utilizando o ,like para consultar substrings especificas dentrode uma coluna
df2.where((F.col('regiao') == 'Norte')).filter('estado like "R%"').show(10)


#utilizando o ,like para consultar substrings especificas dentrode uma coluna, final
df2.where((F.col('regiao') == 'Norte')).filter('estado like "%A"').show(10)


#utilizando o ,like para consultar substrings especificas dentrode uma coluna,inicio e final
df2.where((F.col('regiao') == 'Norte')).filter('estado like "%A%"').show(200)


##############################################################################

_____________________________________________________________________________
#####creating criando columns colunas########################################

valor = 25
df1 = df.withColumn('novo_valor', F.lit(valor))

#criando mais colunas d euma unica vez
df1 = df1.withColumn('coluna1', F.lit('Conteudo 1')).withColumn('Coluna2', F.lit("Conteudo 2"))

df_novo = event.withColumn('conca', F.col('id_evento') * F.col('id_evento'))

##############################################################################

_____________________________________________________________________________
#####somando colunas, sum columns############################################
#somando colunas
df1 = df1.withColumn('soma_obitos_novos_acumulados', F.col('obitosNovos')+ F.col('obitosAcumulados'))

##############################################################################


_____________________________________________________________________________
#####salvar como tabela############################################
df.write.mode('overwrite') \
    .saveAsTable("nome_da_tabela")


df.createOrReplaceTempView("nome da view")

df.createGlobalTempView("nome da view")

##############################################################################

_____________________________________________________________________________
#####query sql############################################
variavel = spark.sql(query)
 
 
 ##############################################################################
 
 
 _____________________________________________________________________________
#####pandas dataframe to spark dataframe######################################

novo_df_spark = df_pandas.createDataFrame()

_____________________________________________________________________________
#####query com tratamento, treatment, divisão, divison#######################

df.select(df.coluna/60).show()

 

# Achar a maior tempo de voo de SEA para outras cidades 
df.filter(df.nome_coluna == "SEA").groupBy().max("nome_coluna").show()


# Achar a menor distancia do voo de PDX para outras cidades 
df.filter(df.nome_coluna == "PDX").groupBy().min("distance").show()


# Duração Média dos Voos da compania delta
df.filter(df.nome_coluna == "DL").filter(df.nome_coluna == "SEA").groupBy().avg("air_time").show()


# Tempo total em Horas no ar 
df.withColumn("duration_hrs", df.air_time/60).groupBy().sum("duration_hrs").show()





 ##############################################################################
 
 
 _____________________________________________________________________________
#####join#####################################################################

 
 # Join os DataFrames 
 df_joined = df1.join(df2, on="coluna_de_igualdade", how="leftouter")
 
 
  ##############################################################################
  
 _____________________________________________________________________________
#####concat################################################################### 
df3 = (df1.withColumn("status", 
          F.when(F.col("casosNovos") > 0, F.concat(df1.casosNovos,F.lit(" casos novos")))
          .otherwise("Não tem casos novos")))
     
  
  ##############################################################################


 _____________________________________________________________________________
#####substringt###################################################################
df4 = df1.withColumn('ano', F.substring('data', 1, 4)).withColumn('mes', F.substring('data', 6, 2)).withColumn('dia', F.substring('data', 9, 2))



  ##############################################################################
  
 
 _____________________________________________________________________________
#####mean################################################################### 

#4) Calcular a média de idade das pessoas
media = df.select(F.mean('idade')).collect()[0][0]

df.groupBy().mean('idade').show()


  ##############################################################################

 _____________________________________________________________________________
#####order by################################################################### 

df.select(F.col('nome'), F.col('idade')).orderBy(F.col('nome').desc()).show()

#6) Mostrar um ranking de pessoas por idade (Do mais novo para o mais velho)
df.select(F.col('nome'), F.col('idade')).orderBy(F.col('idade').asc()).show()


  ##############################################################################


 _____________________________________________________________________________
#####max################################################################### 

# df_nulos.select(F.max('id_evento')).show() # para numeros
# df_nulos.select(F.max(F.length('frequencia_evento'))).show() # para string'


  ##############################################################################
  
 _____________________________________________________________________________
#####group by###################################################################   
  empDF.groupBy("dept_id").count().show()


 _____________________________________________________________________________
#####drop rows, excluir linhas#################################################

dataframe.where(dataframe.college != 'vrs').show()


# drop rows with college vrs
dataframe.where(dataframe.college != 'vrs').show()

# drop missing values
dataframe = dataframe.dropna() #Drop null values, excluir valores nulos

# removing null values in ID column, Drop null values, excluir valores nulos
dataframe.where(dataframe.ID.isNotNull()).show()


# remove the duplicates by column, remover duplicado por coluna
dataframe.dropDuplicates(['Employee NAME']).show()


df.na.drop(subset=["population","type"]) \
   .show(truncate=False)
  ##############################################################################

eventos = pd.read_csv('/content/df_event.csv', sep=';')

eventos.head()

eventos.tail()

help(pd.read_csv)

df.read_html('path') #Ler html

len(html) #retorna um valor, que é a quantidade de tabelas que possui na página html
 
html[0] #Pega o primeiro html da pagina

df = pd.read_json('http://museus.cultura.gov.br/api/event/find?@select=*')

eventos.columns.values #return the names of the columns

dataframe.values #Retorna os valores do data frame em forma de array caso queira fazer operações com numpy

###creating a new df
selec = ['id', 'name', 'shortDescription', 'longDescription'] #list of name of the columns
novo_df = df.filter(items=selec)

df.info() #getting detailed info about df

df.dtypes #show the data type pf each column

pd.DataFrame(dados.dtypes) #Cria um dataframe com o dtypes

pd.DataFrame(dados.dtypes, columns = ['Tipos de dados']) #Cria um dataframe com os tipos de dados e dá um nome para a coluna.

df.shape #return the numbers of lines and columns

dados.shape[0] ### Checando quantidade de linhas

dados.shape[1] # ## Checando quantidade de colunas

df.size #returns the numbers of lines mmultiplied by the numbers of columns

df.describe() # method will do a quick statistical summary for every numerical column

df.sample(n=8) #Sample method allows you to select values randomly from a Series or DataFrame. It is useful when we want to select a random sample from a distribution.

df['column name'] #acess the column, select the column, selecionar a coluna

df['createTimestamp'][0] #Createtimestamp is the name of the column, 0 is the index of the line

df.isnull() #Identifying Missing Values Isnull

df.isna.any() #Isna function returns a dataframe filled with boolean values with true indicating missing values.

index=np.where(novo_df2.acessibilidade.isnull())
novo_df2.loc[index] ###looking for nuls in a column

dataframe = df.loc['valor_linha'], ['nome_col', 'nome_col2']] #Pesquisa, procura, filtra por linhas e colunas

df.isnull.sum() #You can calculate the number of missing values in each column by

df.memory_usage() #returns how much memory each column uses in bytes.

df.nsmallest(5, 'column_name') #Let’s see how we’d go about finding the 5 observations with the smallest value

df.nlargest(5, 'column_name') #Let’s see how we’d go about finding the 5 observations with the largest value

df[0:4] #returns 4 rows

df[['columns', 'i_want', 'to_see']].groupby(['columns_name', 'column_2']).mean() #It makes it easier to unveil the underlying relationships among variables.

novo_df['createTimestamp'] = [i['date'].split(' ')[0] for i in novo_df.createTimestamp] #getting the only date

df.sort_index(by='column_name', ascending=True) #Sorting columns

drop_cols = ['columns', 'collumns2']
df.drop(drop_cols, axis=1, inplace=True)#  is used to remove a row or a column from a dataframe which has a NaN or no values in it, o valor 1 representa que deseja excluir coluna

novo_df = dataframe.drop('c') #Apagar a linha que contém o índice 'c', delete row by index

df.query('2000 < column_name < 4000')[:8]

novo_df['createTimestamp'] = pd.to_datetime(novo_df['createTimestamp']) #alter the type of the column

df.column_name.unique() #select distinct

df.column_name.replace('São José de todos os esportes', 'São José', inplace=True) #Replace the row value, inplace makes persistent in change.

data[data < 5] = 0 #Replace values less than 5 to zero, substitui valores menor que 5 por zero

dataframe[dataframe['nome_coluna'] > 5] #Filter, filtrando uma coluna de um dataframe por valores maiores que 5

novo_df.rename(columns={'nome_antigo':'novo_nome'}, inplace=True) #Rename the column name

novo_df2.acessibilidade.replace(np.nan, 'Não informado', inplace=True) #Replace num values using Numpy-np

novo_df2.shortDescription[417]='novo valor' #Replace values in a row

novo_df2.loc[417] #Look for a row

novo_df2['nova_col'] = "" #Creating a new column, "" is where you insert the values

for name, tipo in zip(novo_df2.name, novo_df2.tipo_museu):
     print(name, tipo) ###For loop in columns, iterating columns

novo_df2['nova_col_2'] = [name+" "+tipo for name, tipo in zip(novo_df2.name, novo_df2.tipo_museu)] #Creating new column concate columns

del dataframe['column name'] #Delete, apaga a coluna

As chaves de um dicionário serão transformadas no nome de uma coluna ao cria um data frame

na_values='o que eu quiser' #argumento na leitura de um arquivo que especifica o que eu quero que substitua os valores nulos, read, null values

df.sum() #Por padrão o sum no pandas faz a soma das linhas

df.sum(axis='nome_col') #Somando os valores de uma coluna, values

df.mean() #Por padrão o mean no pandas faz a média das linhas

df.mean(axis='nome_col', skipna=False) #Calculando a média dos valores de uma coluna, o skipna por padrão faz pular os dados faltantes

novo_df = df.dropna() #Remover dados null, delete null values

novo_df = df[df.notnull()] #Remover dados null, delete null values

df_novo = df.fillna('x') #Replace/substituir/preencher dados faltantes/nulos/null por x

df1.join(df2, how='outer/left/right') #Por padrão o pandas faz o join pelo index

df.pivot() #Pivota o df para melhor entende-lo

df.melt() #Desfaz o pivot

df.drop_duplicates() #Elimina os valores duplicados de um determinado df

tipos_de_imoveis.drop_duplicates(inplace = True) #Elimina os valores duplicados de um determinado df e salva o tratamento

tipos_de_imoveis = pd.DataFrame(tipos_de_imoveis) #Cria um data frame com os tipos de imóveis

df.index #Checa quais os índices do meu dataframe

for i in range(tipos_de_imoveis.shape[0]):
    print(i) ### Criando um índice para meu df

tipos_de_imoveis.index = range(tipos_de_imoveis.shape[0]) # Aplicando a mudanã de index

tipos_de_imoveis.columns.name = 'ID' # Renomeando a coluna do índice

data = [1, 2, 3, 4, 5] ###Criando uma series
s = pd.Series(data)
s

s = pd.Series(data = data, index = range(len(data))) # Criando um series e dando um índice, index pra ele

dados_residencial.index = range(dados_residencial.shape[0]) #criando um índice, index para o df

index = ['linha' + ' ' + str(i) for i in range(5)] # Outra forma de criar um índice

novo_df = pd.concat([df1, df2, df3]) # Concatena vários dfs, coloca um embaixo do outro

novo_df = pd.concat([df1, df2, df3], axis = 1) # Concatena vários dfs, coloca ao lado do outro

list(dados['Tipo'].drop_duplicates()) # Obtendo uma lista dos valores de uma coluna sem os duplicados, distinct, valores diferentes, 
nesse exemplo dados é o nome do dataframe, 'Tipo' é a coluna

novo_dado['Tipo'].isin(residencial) # Checando se a coluna 'Tipo' possui os valores contidos na lista residencial, para cada valor contido Retorna True

Para eu criar um novo dataframe contendo apenas os dados que eu desejo selecionar de determinada coluna, primeiro eu crio uma variável com os dados
selecao = novo_dado['Tipo'].isin(residencial) # No caso residencial é uma lista com os valores que desejo selecionar, depois:
dados_residencial = novo_dado[selecao] # Crio o novo dataframe fazendo uma seleção nele com os dados exatos que desejo

dados_residencial.to_csv('dados/novocsv.csv', sep = ';', index = False) # Exportando, exporting a dafatrame to csv, o index = False é para não duplicar 
o índice ao salvar







eventos = pd.read_csv('/content/df_event.csv', sep=';')

eventos.head()

eventos.tail()

help(pd.read_csv)

df.read_html('path') #Ler html

len(html) #retorna um valor, que é a quantidade de tabelas que possui na página html
 
html[0] #Pega o primeiro html da pagina

df = pd.read_json('http://museus.cultura.gov.br/api/event/find?@select=*')

eventos.columns.values #return the names of the columns

dataframe.values #Retorna os valores do data frame em forma de array caso queira fazer operações com numpy

###creating a new df
selec = ['id', 'name', 'shortDescription', 'longDescription'] #list of name of the columns
novo_df = df.filter(items=selec)

df.info() #getting detailed info about df

df.dtypes #show the data type pf each column

pd.DataFrame(dados.dtypes) #Cria um dataframe com o dtypes

pd.DataFrame(dados.dtypes, columns = ['Tipos de dados']) #Cria um dataframe com os tipos de dados e dá um nome para a coluna.

df.shape #return the numbers of lines and columns

dados.shape[0] ### Checando quantidade de linhas

dados.shape[1] # ## Checando quantidade de colunas

df.size #returns the numbers of lines mmultiplied by the numbers of columns

df.describe() # method will do a quick statistical summary for every numerical column

df.sample(n=8) #Sample method allows you to select values randomly from a Series or DataFrame. It is useful when we want to select a random sample from a distribution.

df['column name'] #acess the column, select the column, selecionar a coluna

df['createTimestamp'][0] #Createtimestamp is the name of the column, 0 is the index of the line

df.isnull() #Identifying Missing Values Isnull

df['Coluna'].isnull() # Retorna True apenas onde os valores da coluna pedida for nulo

df[df['Coluna'].isnull()] # Retorna um df apenas apenas onde os valores da coluna pedida for nulo

df.isna.any() #Isna function returns a dataframe filled with boolean values with true indicating missing values.

index=np.where(novo_df2.acessibilidade.isnull())
novo_df2.loc[index] ###looking for nuls in a column

dataframe = df.loc['valor_linha'], ['nome_col', 'nome_col2']] #Pesquisa, procura, filtra por linhas e colunas

df.isnull.sum() #You can calculate the number of missing values in each column by

df.memory_usage() #returns how much memory each column uses in bytes.

df.nsmallest(5, 'column_name') #Let’s see how we’d go about finding the 5 observations with the smallest value

df.nlargest(5, 'column_name') #Let’s see how we’d go about finding the 5 observations with the largest value

df[0:4] #returns 4 rows

df[['columns', 'i_want', 'to_see']].groupby(['columns_name', 'column_2']).mean() #It makes it easier to unveil the underlying relationships among variables.

novo_df['createTimestamp'] = [i['date'].split(' ')[0] for i in novo_df.createTimestamp] #getting the only date

df.sort_index(by='column_name', ascending=True, inplace = True, axis = 1) #Sorting columns, o argumento by no caso aqui seleciona ordenar por colunas,
axis = 1 diz que é para ordenar também por nome das colunas

df.sort_values(by = 'X', inplace = True) # Ordenando meu dataframe pela coluna 'X'

df.sort_values(by = ['X', 'Y'], inplace = True) # Ordenando meu dataframe por colunas, mais de uma coluna

df.sort_values(by = '3', axis = 1, inplace = True) # Ordenando meu dataframe pelo índice 3

drop_cols = ['columns', 'collumns2']
df.drop(drop_cols, axis=1, inplace=True)#  is used to remove a row or a column from a dataframe which has a NaN or no values in it, o valor 1 representa que deseja excluir coluna

novo_df = dataframe.drop('c') #Apagar a linha que contém o índice 'c', delete row by index

df.query('2000 < column_name < 4000')[:8]

novo_df['createTimestamp'] = pd.to_datetime(novo_df['createTimestamp']) #alter the type of the column

df.column_name.unique() #select distinct

df.column_name.replace('São José de todos os esportes', 'São José', inplace=True) #Replace the row value, inplace makes persistent in change.

data[data < 5] = 0 #Replace values less than 5 to zero, substitui valores menor que 5 por zero

dataframe[dataframe['nome_coluna'] > 5] #Filter, filtrando uma coluna de um dataframe por valores maiores que 5

novo_df.rename(columns={'nome_antigo':'novo_nome'}, inplace=True) #Rename the column name

novo_df2.acessibilidade.replace(np.nan, 'Não informado', inplace=True) #Replace num values using Numpy-np

novo_df2.shortDescription[417]='novo valor' #Replace values in a row

novo_df2.loc[417] #Look for a row

novo_df2['nova_col'] = "" #Creating a new column, "" is where you insert the values

for name, tipo in zip(novo_df2.name, novo_df2.tipo_museu):
     print(name, tipo) ###For loop in columns, iterating columns

novo_df2['nova_col_2'] = [name+" "+tipo for name, tipo in zip(novo_df2.name, novo_df2.tipo_museu)] #Creating new column concate columns

del dataframe['column name'] #Delete, apaga a coluna

As chaves de um dicionário serão transformadas no nome de uma coluna ao cria um data frame

na_values='o que eu quiser' #argumento na leitura de um arquivo que especifica o que eu quero que substitua os valores nulos, read, null values

df.sum() #Por padrão o sum no pandas faz a soma das linhas

df.sum(axis='nome_col') #Somando os valores de uma coluna, values

df.mean() #Por padrão o mean no pandas faz a média das linhas

df.mean(axis='nome_col', skipna=False) #Calculando a média dos valores de uma coluna, o skipna por padrão faz pular os dados faltantes

novo_df = df.dropna() #Remover dados null, delete null values

novo_df = df[df.notnull()] #Remover dados null, delete null values

df_novo = df.fillna('x') #Replace/substituir/preencher dados faltantes/nulos/null por x

df1.join(df2, how='outer/left/right') #Por padrão o pandas faz o join pelo index

df.pivot() #Pivota o df para melhor entende-lo

df.melt() #Desfaz o pivot

df.drop_duplicates() #Elimina os valores duplicados de um determinado df

tipos_de_imoveis.drop_duplicates(inplace = True) #Elimina os valores duplicados de um determinado df e salva o tratamento

tipos_de_imoveis = pd.DataFrame(tipos_de_imoveis) #Cria um data frame com os tipos de imóveis

df.index #Checa quais os índices do meu dataframe

for i in range(tipos_de_imoveis.shape[0]):
    print(i) ### Criando um índice para meu df

tipos_de_imoveis.index = range(tipos_de_imoveis.shape[0]) # Aplicando a mudanã de index

tipos_de_imoveis.columns.name = 'ID' # Renomeando a coluna do índice

data = [1, 2, 3, 4, 5] ###Criando uma series
s = pd.Series(data)
s

s = pd.Series(data = data, index = range(len(data))) # Criando um series e dando um índice, index pra ele

dados_residencial.index = range(dados_residencial.shape[0]) #criando um índice, index para o df

index = ['linha' + ' ' + str(i) for i in range(5)] # Outra forma de criar um índice

novo_df = pd.concat([df1, df2, df3]) # Concatena vários dfs, coloca um embaixo do outro

novo_df = pd.concat([df1, df2, df3], axis = 1) # Concatena vários dfs, coloca ao lado do outro

list(dados['Tipo'].drop_duplicates()) # Obtendo uma lista dos valores de uma coluna sem os duplicados, distinct, valores diferentes, 
nesse exemplo dados é o nome do dataframe, 'Tipo' é a coluna

novo_dado['Tipo'].isin(residencial) # Checando se a coluna 'Tipo' possui os valores contidos na lista residencial, para cada valor contido Retorna True

Para eu criar um novo dataframe contendo apenas os dados que eu desejo selecionar de determinada coluna, primeiro eu crio uma variável com os dados
selecao = novo_dado['Tipo'].isin(residencial) # No caso residencial é uma lista com os valores que desejo selecionar, depois:
dados_residencial = novo_dado[selecao] # Crio o novo dataframe fazendo uma seleção nele com os dados exatos que desejo

dados_residencial.to_csv('dados/novocsv.csv', sep = ';', index = False) # Exportando, exporting a dafatrame to csv, o index = False é para não duplicar 
o índice ao salvar

selecao_ap = dado3['Tipo'] == 'Apartamento' # Uma outra forma de selecioar apenas os dados que eu quero de uma coluna, primeiro eu faço a seleção do que eu quero ver
dado3[selecao_ap] # Depois aplico a seleção ao dataframe
dado3[selecao_ap].shape[0] # Contar, contagem quantidades de apartamentos que possuo


selecao_3 = (dado3['Tipo'] == 'Casa') | (dado3['Tipo'] == 'Casa de Condomínio') | (dado3['Tipo'] == 'Casa de Vila') # Quando quero selecionar vários dados 
de uma coluna por vez, primeiro faço assim, depois:
n3 = dados3[selecao_3] # Aplico a selecao a uma variavel

n4[n4['Area'] < 60] # Validando se os valores foram tratados corretamente, n4 é o nome do df, o que está dentro do colchetes é a condição

n4[(n4['Area'] < 60) & (n4['Area'] > 100)].sum() # Validando se os valores foram tratados corretamente, n4 é o nome do df, o que está dentro do colchetes é a condição

df.dropna(subset = ['Coluna'], inplace = True) # Dropa todos os nulos da coluna pedida.


dado4[dado4['Condominio'].isnull()].shape[0] #Contando valores nulos da coluna condimínio.


novo_df['coluna'] = novo_df['coluna'].round(2) # Arredondando para apenas 2 casas decimais.

dado['tipo agregado'] = dado['tipo'].apply(lambda x: 'Casa' if x in lista else 'Apartamento')


dados_aux = pd.DataFrame(dados[['coluna1', 'coluna2', 'coluna3']]) # Crinado um novo dataframe com base nas colunas que quero do df antigo

dados_aux.pop('coluna x') Deletando, dropando uma coluna.

dados.drop(['coluna1', 'coluna2']) # Dropando 2 colunas de uma vez, mais de uma

dados.drop(['coluna1', 'coluna2'], axis = 1, inplace = True) # axis 1 = coluna, axis 0 = linha 

series.value_counts() # Conta quantos de cada valor possui na series

df['coluna'].value_counts() # Conta quando de cada possui


ll = n4['Tipo'].unique() # Contando quantos tipos tem em uma coluna

n4['Tipo'].count() # Contando os não nulos do dataframe n4

df3.rename(columns={0: "nova"}, inplace=True) # Renomeando colunas, renaming columns

df['coluna_com_numeros'].aggregate(['min', 'max', 'sum']) # Trás algumas informações estatísticas que eu apontar

classes = [0, 2, 4, 6, 100]
labels = ['1 e 2 quartos', '3 e 4 quartos', '5 e 6 quartos', '7 quartos ou mais']
quartos = pd.cut(dados['quartos'], classes, labels = labels) # Criando faixas de valor, cada valor que está na lista chamada clases, é o teto da faixa,
labels é o nome que você dá para a faixa.

sorted(dados['Anos de Estudo'].unique()) # Ordenar uma lista de dados através do sorted

dados['Idade'].min() # Busca o valor mínimo da coluna idade

dados['Idade'].max() # Busca o valor máximo da coluna idade

dados['Sexo'].value_counts(normalize=True) # Calculando a porcentagem

dados['Sexo'].value_counts(normalize=True) * 100 # Calculando a porcentagem já com a multiplicação por 100 para não ter numero com virgula

df_quali.rename(index = {0: 'Masculino', 1: 'Feminino'}, inplace=True) # Renomeando índice

df_quali.rename_axis('Sexo', axis='columns', inplace=True) # Renomeando a coluna do índice

sexo = {0: 'Masculino',
        1: 'Feminino'}

cor = {0: 'Branca',
        1: 'Negra'}

tabela_cruzada = pd.crosstab(dados.Sexo, dados.Cor) # Criar uma tabela cruzando dados que possuo
tabela_cruzada.rename(index = sexo, inplace+True)
tabela_cruzada.rename(columns = cor, inplace+True)


tabela_cruzada = pd.crosstab(dados.Sexo, dados.Cor, normalize=True) # Criar uma tabela cruzando dados que possuo, crosstab com porcentual
tabela_cruzada = pd.crosstab(dados.Sexo, dados.Cor, normalize=True) * 100 # Criar uma tabela cruzando dados que possuo, crosstab com porcentual


tabela_cruzada = pd.crosstab(n4['Tipo'], n4['Bairro'], aggfunc = 'mean', values = n4['Valor']) Criando um crosstab e calculando a média de valor ao mesmo tempo.

pd.cut(x = dados['quartos'], bins= classes, labels = labels, include_lowest=True) # Criando faixas de valor, cada valor que está na lista chamada clases, é o teto da faixa,
labels é o nome que você dá para a faixa, o include lowest é para incluir o menor valor de cada faixa.

pd.value_counts(pd.cut(x = dados['quartos'], bins= classes, labels = labels, include_lowest=True))


percentual = pd.value_counts(pd.cut(x = dados['quartos'], bins= classes, labels = labels, include_lowest=True), normalize=True)


pd.value_counts(pd.cut(x = dados['quartos'], bins= 15, labels = labels, include_lowest=True), sort=False) # Criando um cut com quantidade de classes definidas pela fórmula de 
definição de classes feita com numpy. Caso eu queira ordenas pelas classes devo passar o sorte=False.

df['coluna'].mean() # Calculando a média de uma coluna

df.groupby(['Sexo'])['Renda'].mean() # Média com group by

dataset.groupby('Sexo').mean().loc['H'] # Calculando a média de uma determinada linha

df = df.reset_index() # Ele pega a coluna que está sendo usada de índice, transforma ela em uma coluna do df e cria um novo índice para o df

df.median() # Calculando a mediana

df.mode() # Obtendo a moda do df

df.renda.quantile([0.25, 0.50, 0.75]) # Calculando os quartis, cada valor dentro da lista mostra onde quero dividir meus quartis.

df.renda.quantile([i/10 for i in range(1,10)]) # Calculando os decis

df.renda.quantile([i/100 for i in range(1,100)]) # Calculando os percentis


desvio_medio_absoluto = df['coluna'].mad() # Calcular desvio médio absuluto

df['coluna'].pow(2) # elevar ao quadrado

df['coluna'].var() # Calculando a variância amostral

df['coluna'].std() # Calculando desvio padrão amostral


amostra = dados.Renda.sample(n = 100, random_state = 101) # Criando uma amostra de 100 dados, de forma totalmente aleatória(indicado pelo 101), seleção de amostra

notas.groupby('id_filme').mean()['notas'] # Fazendo um group by e tirando média de uma coluina ao mesmo tempo


















